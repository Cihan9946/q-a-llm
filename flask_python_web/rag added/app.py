from flask import Flask, render_template, request, jsonify, session
import requests
import uuid
import os
from db import init_db, init_settings, save_selected_model, get_selected_model


from db import init_db, save_message, get_history, get_all_sessions, reset_session

from rag_bridge import rag_answer  # yukarÄ±ya ekle
from rag_utils import build_prompt , get_similar_chunks,ask_ollama,rag_ask

app = Flask(__name__)
app.secret_key = os.urandom(24)

OLLAMA_URL = "http://localhost:11434/api/generate"

# Modelleri bir yapÄ± iÃ§inde tutalÄ±m
MODELS = {
    "turkcell-custom": "Turkcell FineTune Model",
    "turkcell-unsloth":"Turkcell FineTune unsloth Model",
    "koc-custom": "KoÃ§ FineTune Model",
    "commencis-custom": "commencis FineTune Model",
    "trendyol-custom": "trendyol FineTune Model"
    
    # Buraya yeni modelleri ekleyebilirsiniz
}

DB_CONFIG = {
    "dbname": "ragdb",
    "user": "postgres",
    "password": "secret",  # kendi ÅŸifreni kullan
    "host": "localhost",
    "port": "5432"
}

@app.route("/")
def index():
    if 'session_id' not in session:
        session['session_id'] = str(uuid.uuid4())

    sid = session['session_id']
    history = get_history(sid)
    all_sessions = get_all_sessions()
    return render_template("chat.html", history=history, all_sessions=all_sessions, models=MODELS)

@app.route("/send_message", methods=["POST"])
def send_message():
    user_msg = request.json.get("message")
    selected_model = request.json.get("model", "turkcell-custom")  # SeÃ§ilen model, default "turkcell-custom"
    sid = session.get('session_id')

    history = get_history(sid)
    bot_msg = generate_response(user_msg, history, selected_model)

    save_message(sid, user_msg, bot_msg)
    return jsonify({"response": bot_msg})

@app.route("/reset", methods=["POST"])
def reset():
    sid = session.get('session_id')
    reset_session(sid)
    return jsonify({"status": "ok"})

@app.route("/switch_session", methods=["POST"])
def switch_session():
    new_sid = request.json.get("session_id")
    session['session_id'] = new_sid
    return jsonify({"status": "switched"})

@app.route("/train_model", methods=["GET", "POST"])
def train_model():
    if request.method == "POST":
        dataset = request.files.get("dataset")
        model_files = request.files.getlist("model_files")
        epochs = request.form.get("epochs")
        batch_size = request.form.get("batch_size")
        
        # ğŸ’¡ DosyalarÄ± ve parametreleri kontrol etmek iÃ§in log at
        print("âœ… Fine-tune baÅŸlatÄ±ldÄ±")
        print("Dataset:", dataset.filename)
        print("Epochs:", epochs)
        print("Batch Size:", batch_size)
        print("Toplam model dosyasÄ±:", len(model_files))

        # Burada eÄŸitim iÅŸlemini baÅŸlatabilirsin

        return "ğŸš€ Model eÄŸitimi baÅŸlatÄ±ldÄ±!"
    
    # EÄŸer GET isteÄŸi gelirse, formu gÃ¶ster
    return render_template("train_model.html")

def generate_response(message, history, model):
    system_prompt = (
    "Sen yalnÄ±zca Link-Cloud ERP hakkÄ±nda konuÅŸan bir yapay zeka asistanÄ±sÄ±n. "
    "Link-Cloud, Link Bilgisayar tarafÄ±ndan geliÅŸtirilen bir ERP yazÄ±lÄ±mÄ±dÄ±r. "
  
    "Sana gelen her mesajÄ± Ã¶nce dikkatlice analiz et. EÄŸer mesaj Link-Cloud ERP ile ilgiliyse cevap ver. "
    "Ama mesaj ERP ile ilgili deÄŸilse kesinlikle cevap Ã¼retme. Bu durumda sadece aÅŸaÄŸÄ±daki cevabÄ± ver:\n\n"
    "'ÃœzgÃ¼nÃ¼m, ben sadece Link-Cloud ERP hakkÄ±nda yardÄ±mcÄ± olabilirim. YardÄ±mcÄ± olabileceÄŸim farklÄ± bir konu hakkÄ±nda sorabilirsiniz "
    "216 522 00 00 numaralÄ± telefondan veya info@linkbilgisayar.com.tr adresinden ulaÅŸabilirsiniz. "
    "Link-Cloud ERP sistemi ile ilgili sorularÄ±nÄ±zÄ± memnuniyetle yanÄ±tlayabilirim.'\n\n"
    " YanÄ±ltÄ±cÄ± veya alakasÄ±z konulara cevap verme. AÅŸaÄŸÄ±daki Ã¶rnekler ERP dÄ±ÅŸÄ± konulara Ã¶rnektir:\n"
    "- Matematik sorularÄ± (Ã¶rneÄŸin: 2+2 kaÃ§ eder?)\n"
    "- Film Ã¶nerisi, dizi tavsiyesi\n"
    "- Hava durumu, saÄŸlÄ±k bilgisi, genel kÃ¼ltÃ¼r\n"
    "- EÄŸlence amaÃ§lÄ± sorular\n\n"
    "Bu tÃ¼r sorular geldiÄŸinde sadece yukarÄ±daki sabit mesajÄ± ver. SakÄ±n baÅŸka bir cevap Ã¼retme."
    "Ã§Ã¶zÃ¼m odaklÄ± ve yol gÃ¶sterici ol"
    )

    # ğŸ” Chat geÃ§miÅŸini oluÅŸtur
    prompt = f"<|system|>\n{system_prompt}\n"
    for item in history:
        prompt += f"KullanÄ±cÄ±: {item['user']}\nAsistan: {item['bot']}\n"
    prompt += f"KullanÄ±cÄ±: {message}\nAsistan:"

    payload = {
        "model": model,  # SeÃ§ilen model buraya ekleniyor
        "prompt": prompt,
        "stream": False
    }

    response = requests.post(OLLAMA_URL, json=payload)
    if response.status_code == 200:
        result = response.json()
        return result.get("response", "").strip()
    else:
        return "âš ï¸ Sunucu hatasÄ±: YanÄ±t alÄ±namadÄ±."
    
    
@app.route("/api_settings", methods=["GET", "POST"])
def api_settings():
    current_model = get_selected_model()

    if request.method == "POST":
        selected_model = request.form.get("selected_model")
        save_selected_model(selected_model)
        current_model = selected_model
        return render_template("api_settings.html", models=MODELS, current_model=current_model, message="Model kaydedildi.")

    return render_template("api_settings.html", models=MODELS, current_model=current_model)






@app.route("/rag_chat", methods=["POST"])
def rag_chat():
    try:
        data = request.json
        user_msg = data.get("message")
        model = data.get("model", "turkcell-custom")
        rag_active = data.get("rag_active", True)  # Default True

        sid = session.get('session_id')  # ğŸ”¹ Oturumu al

        print(f"\nğŸ”µ RAG Ä°STEÄÄ° ALINDI (Durum: {'AKTÄ°F' if rag_active else 'PASÄ°F'})")
        print(f"ğŸ“© Mesaj: {user_msg}")
        print(f"ğŸ¤– Model: {model}")

        # VeritabanÄ±ndan chunk'larÄ± al
        chunks = get_similar_chunks(user_msg)
        print(f"ğŸ“š Bulunan chunk sayÄ±sÄ±: {len(chunks)}")

        if not chunks:
            response = "âš ï¸ RAG: Ä°lgili bilgi bulunamadÄ±"
            print(response)
            save_message(sid, user_msg, response)  # â— Kaydet
            return jsonify({"response": response})

        # Basit prompt template
        context = "\n".join([f"â€¢ {chunk[:200]}..." for chunk in chunks[:3]])  # Ä°lk 3 chunk'Ä±n kÄ±saltÄ±lmÄ±ÅŸ hali
        prompt = f"""<|system|>
AÅŸaÄŸÄ±daki bilgileri kullanarak soruyu cevaplayÄ±n. Bilgi yoksa "Bilgi bulunamadÄ±" deyin.

BaÄŸlam:
{context}

Soru: {user_msg}
Cevap:"""

        print(f"\nğŸ“ Prompt (kÄ±saltÄ±lmÄ±ÅŸ):\n{prompt[:300]}...\n")

        # Ollama'ya istek
        response = ask_ollama({
            "model": model,
            "prompt": prompt,
            "stream": False
        })

        # YanÄ±tÄ± iÅŸaretle
        marked_response = f"{response}\n\nğŸ” [RAG ile oluÅŸturuldu - Kaynaklar: {len(chunks)}]"
        print(f"ğŸŸ¢ YanÄ±t: {response[:200]}...")

        # ğŸ”¸ Sohbet geÃ§miÅŸine kaydet (tÄ±pkÄ± send_message gibi)
        save_message(sid, user_msg, marked_response)

        return jsonify({"response": marked_response})

    except Exception as e:
        error_msg = f"RAG HatasÄ±: {str(e)}"
        print(f"ğŸ”´ {error_msg}")
        return jsonify({"response": error_msg}), 500



@app.route("/test_rag", methods=["GET"])
def test_rag():
    try:
        test_question = "Stok takibi nasÄ±l yapÄ±lÄ±r?"
        print(f"\nğŸ” Test sorusu: {test_question}")
        
        # 1. Embedding oluÅŸtur
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer("all-MiniLM-L6-v2")
        embedding = model.encode(test_question)
        print(f"âœ… VektÃ¶r oluÅŸturuldu (boyut: {len(embedding)})")
        
        # 2. VeritabanÄ± baÄŸlantÄ±sÄ±
        import psycopg2
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # 3. Basit sorgu (dokÃ¼man sayÄ±sÄ±)
        cur.execute("SELECT COUNT(*) FROM documents")
        doc_count = cur.fetchone()[0]
        print(f"ğŸ“Š VeritabanÄ±nda {doc_count} dokÃ¼man bulundu")
        
        # 4. Benzerlik sorgusu
        cur.execute("""
            SELECT content, 1 - (embedding <=> %s) as similarity 
            FROM documents 
            ORDER BY similarity DESC 
            LIMIT 3
        """, (embedding.tolist(),))
        
        results = cur.fetchall()
        print(f"ğŸ” {len(results)} benzer dokÃ¼man bulundu")
        
        if not results:
            return jsonify({
                "status": "error",
                "message": "Benzer dokÃ¼man bulunamadÄ±",
                "suggestion": "VektÃ¶r veritabanÄ±nÄ± kontrol edin"
            })
        
        return jsonify({
            "status": "success",
            "question": test_question,
            "documents_found": doc_count,
            "top_match": {
                "similarity": round(results[0][1], 4),
                "content_preview": results[0][0][:100] + "..."
            }
        })
        
    except Exception as e:
        return jsonify({
            "status": "critical_error",
            "error": str(e),
            "solution": "PostgreSQL baÄŸlantÄ±sÄ±nÄ± ve embedding modelini kontrol edin"
        })

if __name__ == "__main__":
    init_db()
    init_settings()

    from waitress import serve
    serve(app, host="0.0.0.0", port=5000)
