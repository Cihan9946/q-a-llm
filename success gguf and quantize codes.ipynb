{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPkMb81aGzxkVZoFFNuOXvw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5c6705499872413588f0e71eab6eec69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf31f7f4492045a1b23a962ab44232b1","IPY_MODEL_e4d29206279e4200b87b5703e121b7da","IPY_MODEL_96d5adc67c9341f9a5999f4d8d7085a0"],"layout":"IPY_MODEL_c887d6b8103e45eda2c7a5ed785c8198"}},"cf31f7f4492045a1b23a962ab44232b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2924343ceb840a38d6a09a28d58c28c","placeholder":"​","style":"IPY_MODEL_5667b7df485c46c7b08de6ca0f2bbb60","value":"tokenizer_config.json: "}},"e4d29206279e4200b87b5703e121b7da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d86c2ad33ae483195f0ce8990131379","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c2535faedd94013a2220717c189ceb6","value":1}},"96d5adc67c9341f9a5999f4d8d7085a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba1304eeaf8b465291b9957f352f60c3","placeholder":"​","style":"IPY_MODEL_8be0da48e61846039afaba56fbe50004","value":" 1.63k/? [00:00&lt;00:00, 140kB/s]"}},"c887d6b8103e45eda2c7a5ed785c8198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2924343ceb840a38d6a09a28d58c28c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5667b7df485c46c7b08de6ca0f2bbb60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d86c2ad33ae483195f0ce8990131379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1c2535faedd94013a2220717c189ceb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba1304eeaf8b465291b9957f352f60c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be0da48e61846039afaba56fbe50004":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23b32d26a9a2429d99d9304615296bd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7ddf225c4d34f1b93753be4167dd734","IPY_MODEL_885ef5b0ddaf4ac1838c93bc7874fdb3","IPY_MODEL_d614e66c2b904968a6d964e06d01c70e"],"layout":"IPY_MODEL_6b85b48f73ea43b5a2d441cdfa57ca9a"}},"a7ddf225c4d34f1b93753be4167dd734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3e63098b8d540b3842f4547ee113ab7","placeholder":"​","style":"IPY_MODEL_ed7dff27ce99410c8932f269aee9e3c5","value":"tokenizer.model: 100%"}},"885ef5b0ddaf4ac1838c93bc7874fdb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea2c7602a535416ba3d4edeabd6201f9","max":791343,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d55cd222f7c47dd9df231f39f929c77","value":791343}},"d614e66c2b904968a6d964e06d01c70e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c5644263e8847a493e8ba387fce44ec","placeholder":"​","style":"IPY_MODEL_9752264612464b5b9adb331795cc5d1b","value":" 791k/791k [00:00&lt;00:00, 29.0MB/s]"}},"6b85b48f73ea43b5a2d441cdfa57ca9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e63098b8d540b3842f4547ee113ab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed7dff27ce99410c8932f269aee9e3c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea2c7602a535416ba3d4edeabd6201f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d55cd222f7c47dd9df231f39f929c77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c5644263e8847a493e8ba387fce44ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9752264612464b5b9adb331795cc5d1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a05509f0460469fab8b12e1e1bf3faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edaedb506b2e4d40950047ca787422c2","IPY_MODEL_8c3defec9abf4054ac380366cbe6e088","IPY_MODEL_2ec7455018f54b8caf6af33b27aa149d"],"layout":"IPY_MODEL_dc61c61f3ff74329928e05cd8a477bee"}},"edaedb506b2e4d40950047ca787422c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16edb151f7b84151b3bfa6a04a179693","placeholder":"​","style":"IPY_MODEL_2dca2d9509d6485686bb2ae91c65aea8","value":"tokenizer.json: "}},"8c3defec9abf4054ac380366cbe6e088":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b882afc75c3d4aa19337ae4f109f0fdc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_312b9f26c1604392ba5e530fe040e7ff","value":1}},"2ec7455018f54b8caf6af33b27aa149d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e6a5a68bc9b4603b4f02ca29851464f","placeholder":"​","style":"IPY_MODEL_213776a2e0a5430dbe9cac467f4d8a98","value":" 2.96M/? [00:00&lt;00:00, 77.0MB/s]"}},"dc61c61f3ff74329928e05cd8a477bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16edb151f7b84151b3bfa6a04a179693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dca2d9509d6485686bb2ae91c65aea8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b882afc75c3d4aa19337ae4f109f0fdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"312b9f26c1604392ba5e530fe040e7ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e6a5a68bc9b4603b4f02ca29851464f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"213776a2e0a5430dbe9cac467f4d8a98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92e73c0ef4e740d28af5c484d85214b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c619919d5264872af8979ce968b371e","IPY_MODEL_a3c739b3ec7d44a2979fd9f556ab8269","IPY_MODEL_d09148fd359844989f9da7a073804c55"],"layout":"IPY_MODEL_ce418b3311364dbc9f539b1e9e1b5739"}},"6c619919d5264872af8979ce968b371e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab15370c627d488a952a9237d7520609","placeholder":"​","style":"IPY_MODEL_772fdb6d6be34a0ca0619015b98874d0","value":"added_tokens.json: 100%"}},"a3c739b3ec7d44a2979fd9f556ab8269":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23b74cfabb1444cf8c109cc4e236adba","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6345bc11fca74d5ab3528c26318a3191","value":51}},"d09148fd359844989f9da7a073804c55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08d3cf98cad84226a24715ac44f7f5b6","placeholder":"​","style":"IPY_MODEL_cd08bde2434b4839933d88152df8c14f","value":" 51.0/51.0 [00:00&lt;00:00, 6.43kB/s]"}},"ce418b3311364dbc9f539b1e9e1b5739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab15370c627d488a952a9237d7520609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"772fdb6d6be34a0ca0619015b98874d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23b74cfabb1444cf8c109cc4e236adba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6345bc11fca74d5ab3528c26318a3191":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08d3cf98cad84226a24715ac44f7f5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd08bde2434b4839933d88152df8c14f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11348f44c5ee42fa9301b8112a65ba37":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59e5872814b046239ce322e3df1847d7","IPY_MODEL_2911366008f740c0a805464ea1844bcc","IPY_MODEL_b53c1668bdd24779afbb93109b191375"],"layout":"IPY_MODEL_ba9164048ede432281ec3fc4ecc60391"}},"59e5872814b046239ce322e3df1847d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4065cafdf1404b019e2fb3d117754309","placeholder":"​","style":"IPY_MODEL_89fd4c1727284b3785100b8947fdfd71","value":"special_tokens_map.json: 100%"}},"2911366008f740c0a805464ea1844bcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd3870cfe9a84c338eacedbdc627bf7a","max":647,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c093a8031520410cb9eefef590d6b9c0","value":647}},"b53c1668bdd24779afbb93109b191375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2bc867ffd694b57aafd213866f9f6ce","placeholder":"​","style":"IPY_MODEL_721b693f13fe43aca3add621c6cab3e9","value":" 647/647 [00:00&lt;00:00, 89.0kB/s]"}},"ba9164048ede432281ec3fc4ecc60391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4065cafdf1404b019e2fb3d117754309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89fd4c1727284b3785100b8947fdfd71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd3870cfe9a84c338eacedbdc627bf7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c093a8031520410cb9eefef590d6b9c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2bc867ffd694b57aafd213866f9f6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"721b693f13fe43aca3add621c6cab3e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5346c05c3c1f44618f7157b2f8080197":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1ca1de2f88347e1959c6b886eb21080","IPY_MODEL_ad15f5b9a5c844a0a77dec07c13907ff","IPY_MODEL_87ab287e60b5400ab9830dba6ad30acc"],"layout":"IPY_MODEL_b748f11395784ec7b0858d9880ad97c4"}},"e1ca1de2f88347e1959c6b886eb21080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a173e8935da14e76846fbcb164c5b9e5","placeholder":"​","style":"IPY_MODEL_055d5896f76e42f9921ce82d2796f6b4","value":"config.json: 100%"}},"ad15f5b9a5c844a0a77dec07c13907ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3795e4ee90824aa3b47e74be7f338354","max":643,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8be6f9095f3448f88f0e6d56f6c28992","value":643}},"87ab287e60b5400ab9830dba6ad30acc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9db8691d0cd640179193e6b4c7bec322","placeholder":"​","style":"IPY_MODEL_48ef5164b74143348e547075997aaa8d","value":" 643/643 [00:00&lt;00:00, 82.5kB/s]"}},"b748f11395784ec7b0858d9880ad97c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a173e8935da14e76846fbcb164c5b9e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"055d5896f76e42f9921ce82d2796f6b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3795e4ee90824aa3b47e74be7f338354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be6f9095f3448f88f0e6d56f6c28992":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9db8691d0cd640179193e6b4c7bec322":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ef5164b74143348e547075997aaa8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c85f3f50f3884d1f9e2f057d184fa2bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7014a52d1f234cf9b347e1b67d5b9c5f","IPY_MODEL_1d081777445543c18bd804703b09ba49","IPY_MODEL_8e7cce0e0ed64100ad487e40a21734f7"],"layout":"IPY_MODEL_a8567490945f4388a52d42206c91c3f8"}},"7014a52d1f234cf9b347e1b67d5b9c5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a1971889e94366b956ca7a9af41a7d","placeholder":"​","style":"IPY_MODEL_28b3651e202847258bf8866a75472de9","value":"model.safetensors.index.json: "}},"1d081777445543c18bd804703b09ba49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6dafcd72cb04b44bdc7a5a4ef4b0200","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91bc520c869c45959ff8e9da33efe189","value":1}},"8e7cce0e0ed64100ad487e40a21734f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae66a9bb91e64681a0c0dc8142ec3fb2","placeholder":"​","style":"IPY_MODEL_a1e39bbd86394aa9a467d957be1fbac6","value":" 23.9k/? [00:00&lt;00:00, 2.68MB/s]"}},"a8567490945f4388a52d42206c91c3f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a1971889e94366b956ca7a9af41a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28b3651e202847258bf8866a75472de9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6dafcd72cb04b44bdc7a5a4ef4b0200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"91bc520c869c45959ff8e9da33efe189":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae66a9bb91e64681a0c0dc8142ec3fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1e39bbd86394aa9a467d957be1fbac6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb4164eac7f464ab9460c7aea9f3bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3418e042093e419bb77141b8dd1a9b58","IPY_MODEL_299485b041674f42af4f5b573ae94cff","IPY_MODEL_ff2b4a72693046f1953b5744af12c06d"],"layout":"IPY_MODEL_ebb19d82c6634b6a96d08c8411bc696f"}},"3418e042093e419bb77141b8dd1a9b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff158eeb3ae14b9d874dbab85053b00b","placeholder":"​","style":"IPY_MODEL_1ce126c80cca49ed920011296419caee","value":"Fetching 3 files: 100%"}},"299485b041674f42af4f5b573ae94cff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa1df217c6a4159a484c3a7256c6eb9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d7ab385c6f04711bd6756f0e1ed4af9","value":3}},"ff2b4a72693046f1953b5744af12c06d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e431fd592a0f4aab8cd820370a04017e","placeholder":"​","style":"IPY_MODEL_f38f44b788aa4b82beba46dd8bac49a9","value":" 3/3 [00:40&lt;00:00, 40.76s/it]"}},"ebb19d82c6634b6a96d08c8411bc696f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff158eeb3ae14b9d874dbab85053b00b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ce126c80cca49ed920011296419caee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efa1df217c6a4159a484c3a7256c6eb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d7ab385c6f04711bd6756f0e1ed4af9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e431fd592a0f4aab8cd820370a04017e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f38f44b788aa4b82beba46dd8bac49a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ae328d904347dfb0f53f72615eeb42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6f833fe07934fab84ab9e38266e377b","IPY_MODEL_d70ff5e6bdd544e5a600586831192fa3","IPY_MODEL_fd3382cf8c5346cabf6815684dde0080"],"layout":"IPY_MODEL_02113022b3ed44c1810cffc109a474ff"}},"b6f833fe07934fab84ab9e38266e377b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3181e4713d994b12901b18c290d52f87","placeholder":"​","style":"IPY_MODEL_d439865c45ef4e2d9b23d8524a85d486","value":"model-00002-of-00003.safetensors: 100%"}},"d70ff5e6bdd544e5a600586831192fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce11cd0885942ba9b5a616c40723c22","max":4915916080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cace9bc0e53471e9a21c2298f316852","value":4915916080}},"fd3382cf8c5346cabf6815684dde0080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0425978e559d4bf592e183fcbfe98ed3","placeholder":"​","style":"IPY_MODEL_1f696ce6efd7453dbc89289810e9651d","value":" 4.92G/4.92G [00:40&lt;00:00, 188MB/s]"}},"02113022b3ed44c1810cffc109a474ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3181e4713d994b12901b18c290d52f87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d439865c45ef4e2d9b23d8524a85d486":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ce11cd0885942ba9b5a616c40723c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cace9bc0e53471e9a21c2298f316852":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0425978e559d4bf592e183fcbfe98ed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f696ce6efd7453dbc89289810e9651d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddbe301be2824b758ac6964024a850c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9013b53458b4d56ada7b2ac2ff7aed4","IPY_MODEL_d285e6eb9b374ed78b21868f2a54bac6","IPY_MODEL_214b2531e77f477c9f8ba77ea35f9ee2"],"layout":"IPY_MODEL_6e332f9709a94267832ce95cb90b3b9c"}},"a9013b53458b4d56ada7b2ac2ff7aed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72cb23e2f6874bf7a65296562731af60","placeholder":"​","style":"IPY_MODEL_33a20ddb911944129b43eb3e369a5a93","value":"model-00001-of-00003.safetensors: 100%"}},"d285e6eb9b374ed78b21868f2a54bac6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02a8a0c2a5904f27bb35f31ea6a732e2","max":4959685392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01a03bc2354d4fbc8ab76f129c5d0cd2","value":4959685392}},"214b2531e77f477c9f8ba77ea35f9ee2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc289ee0f414d4ab1be912726e2e6f7","placeholder":"​","style":"IPY_MODEL_d5aa3abf6d3b4a639a4bf5edc2b4ebaf","value":" 4.96G/4.96G [00:40&lt;00:00, 254MB/s]"}},"6e332f9709a94267832ce95cb90b3b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72cb23e2f6874bf7a65296562731af60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a20ddb911944129b43eb3e369a5a93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02a8a0c2a5904f27bb35f31ea6a732e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01a03bc2354d4fbc8ab76f129c5d0cd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecc289ee0f414d4ab1be912726e2e6f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5aa3abf6d3b4a639a4bf5edc2b4ebaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf17451961974c7fa5b578bc57fb38d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a6805ea800a4c968a58a510a55c3679","IPY_MODEL_cde3ed3c27c14357b0a8fd1fca58b0fd","IPY_MODEL_ddedc9e67c0f49e69ce7ebea42510185"],"layout":"IPY_MODEL_fe55940580b64346a729878b1b19341b"}},"8a6805ea800a4c968a58a510a55c3679":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e7e4c009e0049efb000b7d420e40893","placeholder":"​","style":"IPY_MODEL_37ba971688f649d8afa00f8265ce9c66","value":"model-00003-of-00003.safetensors: 100%"}},"cde3ed3c27c14357b0a8fd1fca58b0fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37623b0c07fc4b42b15e13972042787c","max":4875823816,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d6db3ead9864600adb762d792ecdef2","value":4875823816}},"ddedc9e67c0f49e69ce7ebea42510185":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda5ff0582ab478cb90d5c9057fac745","placeholder":"​","style":"IPY_MODEL_12b95af4777d459cbee0e3614f79e447","value":" 4.88G/4.88G [00:39&lt;00:00, 142MB/s]"}},"fe55940580b64346a729878b1b19341b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7e4c009e0049efb000b7d420e40893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37ba971688f649d8afa00f8265ce9c66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37623b0c07fc4b42b15e13972042787c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d6db3ead9864600adb762d792ecdef2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dda5ff0582ab478cb90d5c9057fac745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b95af4777d459cbee0e3614f79e447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6c479e25eb04cbc9d368273c8e96717":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bfcfa7436ee4952ba699e85b9cc578e","IPY_MODEL_7beb1d5d9e144f52be8d67c9243e4e27","IPY_MODEL_7e1d277ec2d84babb88bfe4b9f3923a9"],"layout":"IPY_MODEL_99f5b36241ae4a15a27491063d0584ad"}},"1bfcfa7436ee4952ba699e85b9cc578e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21542d8b500d44f68bef373e27ad7c93","placeholder":"​","style":"IPY_MODEL_483bab2cfed5415ea0dd73e214496493","value":"Loading checkpoint shards: 100%"}},"7beb1d5d9e144f52be8d67c9243e4e27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72bdf860a93848c391b772c365b80620","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc85be839ed34da7bf7931151abcec04","value":3}},"7e1d277ec2d84babb88bfe4b9f3923a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e064f9ec99a4035823097b95d0d7e25","placeholder":"​","style":"IPY_MODEL_a2b8c68fb7e3410593905b95649601d9","value":" 3/3 [00:03&lt;00:00,  1.27s/it]"}},"99f5b36241ae4a15a27491063d0584ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21542d8b500d44f68bef373e27ad7c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483bab2cfed5415ea0dd73e214496493":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72bdf860a93848c391b772c365b80620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc85be839ed34da7bf7931151abcec04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e064f9ec99a4035823097b95d0d7e25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b8c68fb7e3410593905b95649601d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba9cc196ffb24da5a4f17397e96e151a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_213625e3b66b4713b979b4479d8d227e","IPY_MODEL_daa8d0cb48364accaa556b4b08b919d8","IPY_MODEL_7f5c9813527041d8a835a360d2015707"],"layout":"IPY_MODEL_0657b842f4ee4b7a8054e01dccb3c361"}},"213625e3b66b4713b979b4479d8d227e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5d0f13e38e4f77aaa1b806f145f10a","placeholder":"​","style":"IPY_MODEL_c4b6680ea2a3476e8228f72f9665fb5a","value":"generation_config.json: 100%"}},"daa8d0cb48364accaa556b4b08b919d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d93eee05dd24919b31461036cf4fa84","max":111,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7026b99ecfa543c986cccb9eecc6ea99","value":111}},"7f5c9813527041d8a835a360d2015707":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23a519dc64cf4447953752073877e845","placeholder":"​","style":"IPY_MODEL_da95678ecae041c296dc3e0f6ced3cdd","value":" 111/111 [00:00&lt;00:00, 14.4kB/s]"}},"0657b842f4ee4b7a8054e01dccb3c361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb5d0f13e38e4f77aaa1b806f145f10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b6680ea2a3476e8228f72f9665fb5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d93eee05dd24919b31461036cf4fa84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7026b99ecfa543c986cccb9eecc6ea99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23a519dc64cf4447953752073877e845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da95678ecae041c296dc3e0f6ced3cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rzDvu6FqwV9","executionInfo":{"status":"ok","timestamp":1753532586167,"user_tz":-180,"elapsed":71875,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"5f2abffd-1f88-4814-f40a-2d2dc892e717"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers peft accelerate sentencepiece\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_EQ71NhqyGR","executionInfo":{"status":"ok","timestamp":1753532613660,"user_tz":-180,"elapsed":25069,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"a0d0d5cc-47fc-4886-a2c9-2eb55f2b2e1d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel\n","import os\n","\n","base_model_id = \"TURKCELL/Turkcell-LLM-7b-v1\"  # Orijinal model\n","lora_path = \"/content/drive/MyDrive/turkcell_lora_finetuned\"  # Fine-tune sonrası LoRA klasörü\n","merged_output = \"/content/drive/MyDrive/merged_model_new\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n","model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True)\n","\n","model = PeftModel.from_pretrained(model, lora_path)\n","model = model.merge_and_unload()\n","\n","os.makedirs(merged_output, exist_ok=True)\n","model.save_pretrained(merged_output)\n","tokenizer.save_pretrained(merged_output)\n","\n","print(\"✅ Merge tamamlandı:\", merged_output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581,"referenced_widgets":["5c6705499872413588f0e71eab6eec69","cf31f7f4492045a1b23a962ab44232b1","e4d29206279e4200b87b5703e121b7da","96d5adc67c9341f9a5999f4d8d7085a0","c887d6b8103e45eda2c7a5ed785c8198","d2924343ceb840a38d6a09a28d58c28c","5667b7df485c46c7b08de6ca0f2bbb60","8d86c2ad33ae483195f0ce8990131379","1c2535faedd94013a2220717c189ceb6","ba1304eeaf8b465291b9957f352f60c3","8be0da48e61846039afaba56fbe50004","23b32d26a9a2429d99d9304615296bd2","a7ddf225c4d34f1b93753be4167dd734","885ef5b0ddaf4ac1838c93bc7874fdb3","d614e66c2b904968a6d964e06d01c70e","6b85b48f73ea43b5a2d441cdfa57ca9a","c3e63098b8d540b3842f4547ee113ab7","ed7dff27ce99410c8932f269aee9e3c5","ea2c7602a535416ba3d4edeabd6201f9","5d55cd222f7c47dd9df231f39f929c77","1c5644263e8847a493e8ba387fce44ec","9752264612464b5b9adb331795cc5d1b","8a05509f0460469fab8b12e1e1bf3faa","edaedb506b2e4d40950047ca787422c2","8c3defec9abf4054ac380366cbe6e088","2ec7455018f54b8caf6af33b27aa149d","dc61c61f3ff74329928e05cd8a477bee","16edb151f7b84151b3bfa6a04a179693","2dca2d9509d6485686bb2ae91c65aea8","b882afc75c3d4aa19337ae4f109f0fdc","312b9f26c1604392ba5e530fe040e7ff","9e6a5a68bc9b4603b4f02ca29851464f","213776a2e0a5430dbe9cac467f4d8a98","92e73c0ef4e740d28af5c484d85214b7","6c619919d5264872af8979ce968b371e","a3c739b3ec7d44a2979fd9f556ab8269","d09148fd359844989f9da7a073804c55","ce418b3311364dbc9f539b1e9e1b5739","ab15370c627d488a952a9237d7520609","772fdb6d6be34a0ca0619015b98874d0","23b74cfabb1444cf8c109cc4e236adba","6345bc11fca74d5ab3528c26318a3191","08d3cf98cad84226a24715ac44f7f5b6","cd08bde2434b4839933d88152df8c14f","11348f44c5ee42fa9301b8112a65ba37","59e5872814b046239ce322e3df1847d7","2911366008f740c0a805464ea1844bcc","b53c1668bdd24779afbb93109b191375","ba9164048ede432281ec3fc4ecc60391","4065cafdf1404b019e2fb3d117754309","89fd4c1727284b3785100b8947fdfd71","dd3870cfe9a84c338eacedbdc627bf7a","c093a8031520410cb9eefef590d6b9c0","a2bc867ffd694b57aafd213866f9f6ce","721b693f13fe43aca3add621c6cab3e9","5346c05c3c1f44618f7157b2f8080197","e1ca1de2f88347e1959c6b886eb21080","ad15f5b9a5c844a0a77dec07c13907ff","87ab287e60b5400ab9830dba6ad30acc","b748f11395784ec7b0858d9880ad97c4","a173e8935da14e76846fbcb164c5b9e5","055d5896f76e42f9921ce82d2796f6b4","3795e4ee90824aa3b47e74be7f338354","8be6f9095f3448f88f0e6d56f6c28992","9db8691d0cd640179193e6b4c7bec322","48ef5164b74143348e547075997aaa8d","c85f3f50f3884d1f9e2f057d184fa2bd","7014a52d1f234cf9b347e1b67d5b9c5f","1d081777445543c18bd804703b09ba49","8e7cce0e0ed64100ad487e40a21734f7","a8567490945f4388a52d42206c91c3f8","f8a1971889e94366b956ca7a9af41a7d","28b3651e202847258bf8866a75472de9","b6dafcd72cb04b44bdc7a5a4ef4b0200","91bc520c869c45959ff8e9da33efe189","ae66a9bb91e64681a0c0dc8142ec3fb2","a1e39bbd86394aa9a467d957be1fbac6","ceb4164eac7f464ab9460c7aea9f3bbe","3418e042093e419bb77141b8dd1a9b58","299485b041674f42af4f5b573ae94cff","ff2b4a72693046f1953b5744af12c06d","ebb19d82c6634b6a96d08c8411bc696f","ff158eeb3ae14b9d874dbab85053b00b","1ce126c80cca49ed920011296419caee","efa1df217c6a4159a484c3a7256c6eb9","4d7ab385c6f04711bd6756f0e1ed4af9","e431fd592a0f4aab8cd820370a04017e","f38f44b788aa4b82beba46dd8bac49a9","95ae328d904347dfb0f53f72615eeb42","b6f833fe07934fab84ab9e38266e377b","d70ff5e6bdd544e5a600586831192fa3","fd3382cf8c5346cabf6815684dde0080","02113022b3ed44c1810cffc109a474ff","3181e4713d994b12901b18c290d52f87","d439865c45ef4e2d9b23d8524a85d486","6ce11cd0885942ba9b5a616c40723c22","3cace9bc0e53471e9a21c2298f316852","0425978e559d4bf592e183fcbfe98ed3","1f696ce6efd7453dbc89289810e9651d","ddbe301be2824b758ac6964024a850c4","a9013b53458b4d56ada7b2ac2ff7aed4","d285e6eb9b374ed78b21868f2a54bac6","214b2531e77f477c9f8ba77ea35f9ee2","6e332f9709a94267832ce95cb90b3b9c","72cb23e2f6874bf7a65296562731af60","33a20ddb911944129b43eb3e369a5a93","02a8a0c2a5904f27bb35f31ea6a732e2","01a03bc2354d4fbc8ab76f129c5d0cd2","ecc289ee0f414d4ab1be912726e2e6f7","d5aa3abf6d3b4a639a4bf5edc2b4ebaf","bf17451961974c7fa5b578bc57fb38d3","8a6805ea800a4c968a58a510a55c3679","cde3ed3c27c14357b0a8fd1fca58b0fd","ddedc9e67c0f49e69ce7ebea42510185","fe55940580b64346a729878b1b19341b","7e7e4c009e0049efb000b7d420e40893","37ba971688f649d8afa00f8265ce9c66","37623b0c07fc4b42b15e13972042787c","7d6db3ead9864600adb762d792ecdef2","dda5ff0582ab478cb90d5c9057fac745","12b95af4777d459cbee0e3614f79e447","a6c479e25eb04cbc9d368273c8e96717","1bfcfa7436ee4952ba699e85b9cc578e","7beb1d5d9e144f52be8d67c9243e4e27","7e1d277ec2d84babb88bfe4b9f3923a9","99f5b36241ae4a15a27491063d0584ad","21542d8b500d44f68bef373e27ad7c93","483bab2cfed5415ea0dd73e214496493","72bdf860a93848c391b772c365b80620","bc85be839ed34da7bf7931151abcec04","5e064f9ec99a4035823097b95d0d7e25","a2b8c68fb7e3410593905b95649601d9","ba9cc196ffb24da5a4f17397e96e151a","213625e3b66b4713b979b4479d8d227e","daa8d0cb48364accaa556b4b08b919d8","7f5c9813527041d8a835a360d2015707","0657b842f4ee4b7a8054e01dccb3c361","bb5d0f13e38e4f77aaa1b806f145f10a","c4b6680ea2a3476e8228f72f9665fb5a","7d93eee05dd24919b31461036cf4fa84","7026b99ecfa543c986cccb9eecc6ea99","23a519dc64cf4447953752073877e845","da95678ecae041c296dc3e0f6ced3cdd"]},"id":"ZG7fWLa2qyC6","executionInfo":{"status":"ok","timestamp":1753532793636,"user_tz":-180,"elapsed":176736,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"683cc251-3683-4051-9942-cfe84f90e4aa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c6705499872413588f0e71eab6eec69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/791k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b32d26a9a2429d99d9304615296bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a05509f0460469fab8b12e1e1bf3faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e73c0ef4e740d28af5c484d85214b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11348f44c5ee42fa9301b8112a65ba37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/643 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5346c05c3c1f44618f7157b2f8080197"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c85f3f50f3884d1f9e2f057d184fa2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceb4164eac7f464ab9460c7aea9f3bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ae328d904347dfb0f53f72615eeb42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddbe301be2824b758ac6964024a850c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf17451961974c7fa5b578bc57fb38d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c479e25eb04cbc9d368273c8e96717"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9cc196ffb24da5a4f17397e96e151a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Merge tamamlandı: /content/drive/MyDrive/merged_model_new\n"]}]},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y cmake build-essential\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lewx1bEOqyBH","executionInfo":{"status":"ok","timestamp":1753533400821,"user_tz":-180,"elapsed":9248,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"83463fcb-6997-47e8-a2c5-25133f4bec4d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,768 kB]\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,471 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,142 kB]\n","Fetched 23.6 MB in 5s (4,930 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}]},{"cell_type":"code","source":["!rm -rf llama.cpp\n","%cd /content/llama.cpp\n","!mkdir build\n","%cd build\n","!cmake ..\n","!cmake --build . --config Release\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oENIhvd8vBte","executionInfo":{"status":"ok","timestamp":1753533903969,"user_tz":-180,"elapsed":472721,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"0c4129cd-10b9-4516-d401-82b5414e74c2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/llama.cpp\n","/content/llama.cpp/build\n","-- The C compiler identification is GNU 11.4.0\n","-- The CXX compiler identification is GNU 11.4.0\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Check for working C compiler: /usr/bin/cc - skipped\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Found Git: /usr/bin/git (found version \"2.34.1\")\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n","-- Found Threads: TRUE\n","-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n","-- CMAKE_SYSTEM_PROCESSOR: x86_64\n","-- GGML_SYSTEM_ARCH: x86\n","-- Including CPU backend\n","-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n","-- Found OpenMP: TRUE (found version \"4.5\")\n","-- x86 detected\n","-- Adding CPU backend variant ggml-cpu: -march=native \n","-- ggml version: 0.0.5996\n","-- ggml commit:  11dd5a44\n","-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n","-- Configuring done (1.8s)\n","-- Generating done (0.2s)\n","-- Build files have been written to: /content/llama.cpp/build\n","[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n","[  4%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n","[  4%] Built target ggml-base\n","[  5%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n","[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n","[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n","[ 11%] Built target ggml-cpu\n","[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n","[ 11%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n","[ 11%] Built target ggml\n","[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n","[ 22%] \u001b[32m\u001b[1mLinking CXX shared library ../bin/libllama.so\u001b[0m\n","[ 22%] Built target llama\n","[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n","[ 22%] Built target build_info\n","[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n","[ 28%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n","[ 28%] Built target common\n","[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n","[ 28%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n","[ 28%] Built target test-tokenizer-0\n","[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n","[ 29%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-sampling\u001b[0m\n","[ 29%] Built target test-sampling\n","[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n","[ 30%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n","[ 30%] Built target test-grammar-parser\n","[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n","[ 31%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n","[ 31%] Built target test-grammar-integration\n","[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n","[ 32%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n","[ 32%] Built target test-llama-grammar\n","[ 32%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n","[ 33%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat\u001b[0m\n","[ 33%] Built target test-chat\n","[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n","[ 35%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n","[ 35%] Built target test-json-schema-to-grammar\n","[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n","[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n","[ 36%] Built target test-quantize-stats\n","[ 36%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n","[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n","[ 36%] Built target test-gbnf-validator\n","[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n","[ 37%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n","[ 37%] Built target test-tokenizer-1-bpe\n","[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n","[ 38%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n","[ 38%] Built target test-tokenizer-1-spm\n","[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o\u001b[0m\n","[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o\u001b[0m\n","[ 39%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-parser\u001b[0m\n","[ 39%] Built target test-chat-parser\n","[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n","[ 41%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-chat-template\u001b[0m\n","[ 41%] Built target test-chat-template\n","[ 41%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o\u001b[0m\n","[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o\u001b[0m\n","[ 42%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-json-partial\u001b[0m\n","[ 42%] Built target test-json-partial\n","[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n","[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n","[ 43%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-log\u001b[0m\n","[ 43%] Built target test-log\n","[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o\u001b[0m\n","[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o\u001b[0m\n","[ 44%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-regex-partial\u001b[0m\n","[ 44%] Built target test-regex-partial\n","[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o\u001b[0m\n","[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o\u001b[0m\n","[ 46%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-thread-safety\u001b[0m\n","[ 46%] Built target test-thread-safety\n","[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n","[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n","[ 47%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n","[ 47%] Built target test-arg-parser\n","[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n","[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n","[ 49%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-gguf\u001b[0m\n","[ 49%] Built target test-gguf\n","[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n","[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n","[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n","[ 50%] Built target test-backend-ops\n","[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n","[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n","[ 51%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n","[ 51%] Built target test-model-load-cancel\n","[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n","[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n","[ 53%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-autorelease\u001b[0m\n","[ 53%] Built target test-autorelease\n","[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n","[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n","[ 54%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-barrier\u001b[0m\n","[ 54%] Built target test-barrier\n","[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n","[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n","[ 56%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n","[ 56%] Built target test-quantize-fns\n","[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n","[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n","[ 57%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n","[ 57%] Built target test-quantize-perf\n","[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n","[ 58%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-rope\u001b[0m\n","[ 58%] Built target test-rope\n","[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\u001b[0m\n","[ 59%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n","[ 60%] \u001b[32m\u001b[1mLinking CXX shared library ../../bin/libmtmd.so\u001b[0m\n","[ 60%] Built target mtmd\n","[ 61%] \u001b[32mBuilding C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\u001b[0m\n","[ 61%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-mtmd-c-api\u001b[0m\n","[ 61%] Built target test-mtmd-c-api\n","[ 61%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n","[ 62%] \u001b[32m\u001b[1mLinking C executable ../bin/test-c\u001b[0m\n","[ 62%] Built target test-c\n","[ 62%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n","[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched\u001b[0m\n","[ 63%] Built target llama-batched\n","[ 63%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n","[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n","[ 63%] Built target llama-embedding\n","[ 64%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n","[ 64%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n","[ 64%] Built target llama-eval-callback\n","[ 64%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n","[ 64%] Built target sha256\n","[ 65%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n","[ 65%] Built target xxhash\n","[ 66%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n","[ 66%] Built target sha1\n","[ 67%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n","[ 67%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n","[ 67%] Built target llama-gguf-hash\n","[ 68%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n","[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n","[ 68%] Built target llama-gguf\n","[ 68%] \u001b[32mBuilding CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o\u001b[0m\n","[ 69%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gritlm\u001b[0m\n","[ 69%] Built target llama-gritlm\n","[ 70%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n","[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n","[ 70%] Built target llama-lookahead\n","[ 71%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n","[ 71%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n","[ 71%] Built target llama-lookup\n","[ 71%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n","[ 72%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n","[ 72%] Built target llama-lookup-create\n","[ 72%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n","[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n","[ 73%] Built target llama-lookup-merge\n","[ 73%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n","[ 73%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n","[ 73%] Built target llama-lookup-stats\n","[ 74%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n","[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n","[ 74%] Built target llama-parallel\n","[ 74%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n","[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n","[ 75%] Built target llama-passkey\n","[ 75%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n","[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n","[ 76%] Built target llama-retrieval\n","[ 76%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n","[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n","[ 77%] Built target llama-save-load-state\n","[ 77%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n","[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple\u001b[0m\n","[ 77%] Built target llama-simple\n","[ 78%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n","[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n","[ 78%] Built target llama-simple-chat\n","[ 79%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n","[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n","[ 79%] Built target llama-speculative\n","[ 79%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n","[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n","[ 80%] Built target llama-speculative-simple\n","[ 80%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n","[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n","[ 80%] Built target llama-gen-docs\n","[ 80%] \u001b[32mBuilding CXX object examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o\u001b[0m\n","[ 81%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-finetune\u001b[0m\n","[ 81%] Built target llama-finetune\n","[ 81%] \u001b[32mBuilding CXX object examples/diffusion/CMakeFiles/llama-diffusion-cli.dir/diffusion-cli.cpp.o\u001b[0m\n","[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-diffusion-cli\u001b[0m\n","[ 82%] Built target llama-diffusion-cli\n","[ 82%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n","[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n","[ 83%] Built target llama-convert-llama2c-to-ggml\n","[ 84%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n","[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n","[ 84%] Built target llama-vdot\n","[ 84%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n","[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n","[ 84%] Built target llama-q8dot\n","[ 84%] \u001b[32mBuilding CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n","[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n","[ 84%] Built target llama-batched-bench\n","[ 84%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n","[ 85%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n","[ 85%] Built target llama-gguf-split\n","[ 85%] \u001b[32mBuilding CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n","[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n","[ 86%] Built target llama-imatrix\n","[ 87%] \u001b[32mBuilding CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n","[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-bench\u001b[0m\n","[ 87%] Built target llama-bench\n","[ 88%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n","[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cli\u001b[0m\n","[ 88%] Built target llama-cli\n","[ 88%] \u001b[32mBuilding CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n","[ 89%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n","[ 89%] Built target llama-perplexity\n","[ 90%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n","[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n","[ 90%] Built target llama-quantize\n","[ 91%] \u001b[34m\u001b[1mGenerating loading.html.hpp\u001b[0m\n","[ 91%] \u001b[34m\u001b[1mGenerating index.html.gz.hpp\u001b[0m\n","[ 91%] \u001b[32mBuilding CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n","[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-server\u001b[0m\n","[ 92%] Built target llama-server\n","[ 92%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n","[ 93%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n","[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-run\u001b[0m\n","[ 93%] Built target llama-run\n","[ 93%] \u001b[32mBuilding CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n","[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n","[ 94%] Built target llama-tokenize\n","[ 94%] \u001b[32mBuilding CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n","[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-tts\u001b[0m\n","[ 94%] Built target llama-tts\n","[ 94%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n","[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n","[ 94%] Built target llama-llava-cli\n","[ 94%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n","[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n","[ 95%] Built target llama-gemma3-cli\n","[ 96%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n","[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n","[ 96%] Built target llama-minicpmv-cli\n","[ 97%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\u001b[0m\n","[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n","[ 97%] Built target llama-qwen2vl-cli\n","[ 98%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n","[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n","[ 98%] Built target llama-mtmd-cli\n","[ 98%] \u001b[32mBuilding CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n","[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n","[ 99%] Built target llama-cvector-generator\n","[100%] \u001b[32mBuilding CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n","[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n","[100%] Built target llama-export-lora\n"]}]},{"cell_type":"code","source":["!ls -lh bin\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9k0a47JZxGpX","executionInfo":{"status":"ok","timestamp":1753534013706,"user_tz":-180,"elapsed":115,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"815cf3c0-660f-4331-e7e0-7a20e6baf8eb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["total 81M\n","-rwxr-xr-x 1 root root 673K Jul 26 12:37 libggml-base.so\n","-rwxr-xr-x 1 root root 852K Jul 26 12:37 libggml-cpu.so\n","-rwxr-xr-x 1 root root  54K Jul 26 12:37 libggml.so\n","-rwxr-xr-x 1 root root 2.4M Jul 26 12:39 libllama.so\n","-rwxr-xr-x 1 root root 754K Jul 26 12:42 libmtmd.so\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-batched\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-batched-bench\n","-rwxr-xr-x 1 root root 493K Jul 26 12:43 llama-bench\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-cli\n","-rwxr-xr-x 1 root root 344K Jul 26 12:43 llama-convert-llama2c-to-ggml\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:45 llama-cvector-generator\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-diffusion-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-embedding\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-eval-callback\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:45 llama-export-lora\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-finetune\n","-rwxr-xr-x 1 root root  17K Jul 26 12:44 llama-gemma3-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-gen-docs\n","-rwxr-xr-x 1 root root  28K Jul 26 12:42 llama-gguf\n","-rwxr-xr-x 1 root root 102K Jul 26 12:42 llama-gguf-hash\n","-rwxr-xr-x 1 root root  48K Jul 26 12:43 llama-gguf-split\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-gritlm\n","-rwxr-xr-x 1 root root 2.3M Jul 26 12:43 llama-imatrix\n","-rwxr-xr-x 1 root root  17K Jul 26 12:44 llama-llava-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-lookahead\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-lookup\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-lookup-create\n","-rwxr-xr-x 1 root root  69K Jul 26 12:42 llama-lookup-merge\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:42 llama-lookup-stats\n","-rwxr-xr-x 1 root root  17K Jul 26 12:44 llama-minicpmv-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:44 llama-mtmd-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-parallel\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-passkey\n","-rwxr-xr-x 1 root root 2.3M Jul 26 12:43 llama-perplexity\n","-rwxr-xr-x 1 root root  21K Jul 26 12:43 llama-q8dot\n","-rwxr-xr-x 1 root root 355K Jul 26 12:43 llama-quantize\n","-rwxr-xr-x 1 root root  17K Jul 26 12:44 llama-qwen2vl-cli\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-retrieval\n","-rwxr-xr-x 1 root root 1.8M Jul 26 12:44 llama-run\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-save-load-state\n","-rwxr-xr-x 1 root root 4.9M Jul 26 12:44 llama-server\n","-rwxr-xr-x 1 root root  27K Jul 26 12:43 llama-simple\n","-rwxr-xr-x 1 root root  32K Jul 26 12:43 llama-simple-chat\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-speculative\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:43 llama-speculative-simple\n","-rwxr-xr-x 1 root root 316K Jul 26 12:44 llama-tokenize\n","-rwxr-xr-x 1 root root 2.3M Jul 26 12:44 llama-tts\n","-rwxr-xr-x 1 root root  22K Jul 26 12:43 llama-vdot\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:41 test-arg-parser\n","-rwxr-xr-x 1 root root  18K Jul 26 12:42 test-autorelease\n","-rwxr-xr-x 1 root root 710K Jul 26 12:42 test-backend-ops\n","-rwxr-xr-x 1 root root  22K Jul 26 12:42 test-barrier\n","-rwxr-xr-x 1 root root  16K Jul 26 12:42 test-c\n","-rwxr-xr-x 1 root root 1.8M Jul 26 12:41 test-chat\n","-rwxr-xr-x 1 root root 629K Jul 26 12:41 test-chat-parser\n","-rwxr-xr-x 1 root root 1.7M Jul 26 12:41 test-chat-template\n","-rwxr-xr-x 1 root root  27K Jul 26 12:41 test-gbnf-validator\n","-rwxr-xr-x 1 root root  76K Jul 26 12:41 test-gguf\n","-rwxr-xr-x 1 root root 717K Jul 26 12:41 test-grammar-integration\n","-rwxr-xr-x 1 root root  41K Jul 26 12:40 test-grammar-parser\n","-rwxr-xr-x 1 root root 227K Jul 26 12:41 test-json-partial\n","-rwxr-xr-x 1 root root 706K Jul 26 12:41 test-json-schema-to-grammar\n","-rwxr-xr-x 1 root root  46K Jul 26 12:41 test-llama-grammar\n","-rwxr-xr-x 1 root root  34K Jul 26 12:41 test-log\n","-rwxr-xr-x 1 root root  17K Jul 26 12:42 test-model-load-cancel\n","-rwxr-xr-x 1 root root  17K Jul 26 12:42 test-mtmd-c-api\n","-rwxr-xr-x 1 root root  18K Jul 26 12:42 test-quantize-fns\n","-rwxr-xr-x 1 root root  41K Jul 26 12:42 test-quantize-perf\n","-rwxr-xr-x 1 root root 213K Jul 26 12:41 test-quantize-stats\n","-rwxr-xr-x 1 root root 383K Jul 26 12:41 test-regex-partial\n","-rwxr-xr-x 1 root root  21K Jul 26 12:42 test-rope\n","-rwxr-xr-x 1 root root  50K Jul 26 12:40 test-sampling\n","-rwxr-xr-x 1 root root 2.2M Jul 26 12:41 test-thread-safety\n","-rwxr-xr-x 1 root root 326K Jul 26 12:40 test-tokenizer-0\n","-rwxr-xr-x 1 root root 308K Jul 26 12:41 test-tokenizer-1-bpe\n","-rwxr-xr-x 1 root root 308K Jul 26 12:41 test-tokenizer-1-spm\n"]}]},{"cell_type":"code","source":["!ls -lh | grep convert_hf_to_gguf.py\n","!ls -lh | grep quantize\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGis0RQUuMWF","executionInfo":{"status":"ok","timestamp":1753533296769,"user_tz":-180,"elapsed":211,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"bdf7a586-1f60-473b-d283-7f267ca3529e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["-rwxr-xr-x  1 root root 359K Jul 26 12:27 convert_hf_to_gguf.py\n"]}]},{"cell_type":"code","source":["!python3 /content/llama.cpp/convert_hf_to_gguf.py \\\n","  --outfile /content/output_model_f32.gguf \\\n","  --outtype f32 \\\n","  /content/drive/MyDrive/merged_model_new\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik6Yw_8iqx_K","executionInfo":{"status":"ok","timestamp":1753533001748,"user_tz":-180,"elapsed":131322,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"38bc9169-1b38-4e4c-c10e-5895f823bc55"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:hf-to-gguf:Loading model: merged_model_new\n","INFO:hf-to-gguf:Model architecture: MistralForCausalLM\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00006.safetensors'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float32 --> F32, shape = {4096, 48353}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00006.safetensors'\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00006.safetensors'\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00006.safetensors'\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00005-of-00006.safetensors'\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:gguf: loading model part 'model-00006-of-00006.safetensors'\n","INFO:hf-to-gguf:output.weight,               torch.float32 --> F32, shape = {4096, 48353}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float32 --> F32, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float32 --> F32, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float32 --> F32, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float32 --> F32, shape = {4096, 1024}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float32 --> F32, shape = {4096}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 32768\n","INFO:hf-to-gguf:gguf: embedding length = 4096\n","INFO:hf-to-gguf:gguf: feed forward length = 14336\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 8\n","INFO:hf-to-gguf:gguf: rope theta = 10000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 0\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:hf-to-gguf:Set model tokenizer\n","WARNING:gguf.vocab:Unknown separator token '<|im_start|>' in TemplateProcessing<pair>\n","INFO:gguf.vocab:Setting special token type bos to 48351\n","INFO:gguf.vocab:Setting special token type eos to 48352\n","INFO:gguf.vocab:Setting special token type unk to 0\n","INFO:gguf.vocab:Setting special token type pad to 48352\n","INFO:gguf.vocab:Setting add_bos_token to True\n","INFO:gguf.vocab:Setting add_sep_token to False\n","INFO:gguf.vocab:Setting add_eos_token to False\n","INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{{'<|im_start|>' + message['role'] + '\n","' + message['content'] + '<|im_end|>' + '\n","'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n","' }}{% endif %}\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:/content/output_model_f32.gguf: n_tensors = 291, total_size = 29.5G\n","Writing: 100% 29.5G/29.5G [02:03<00:00, 240Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to /content/output_model_f32.gguf\n"]}]},{"cell_type":"code","source":["%cd /content/llama.cpp\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uD0IiZkZuBE7","executionInfo":{"status":"ok","timestamp":1753533139178,"user_tz":-180,"elapsed":12,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"88f1e0b3-b3a4-47a9-e881-a673c6fe40ca"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/llama.cpp\n"]}]},{"cell_type":"code","source":["!./bin/llama-quantize /content/output_model_f32.gguf /content/model_q4_0.gguf q4_0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMw-r74lqx8-","executionInfo":{"status":"ok","timestamp":1753534284865,"user_tz":-180,"elapsed":117085,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}},"outputId":"7f643214-6ce0-4742-e667-7c091263ea79"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["main: build = 5996 (11dd5a44)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing '/content/output_model_f32.gguf' to '/content/model_q4_0.gguf' as Q4_0\n","llama_model_loader: loaded meta data with 30 key-value pairs and 291 tensors from /content/output_model_f32.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Merged_Model_New\n","llama_model_loader: - kv   3:                         general.size_label str              = 7.4B\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                       llama.context_length u32              = 32768\n","llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n","llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n","llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  12:                          general.file_type u32              = 0\n","llama_model_loader: - kv  13:                           llama.vocab_size u32              = 48353\n","llama_model_loader: - kv  14:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n","llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = default\n","llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,48353]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  19:                      tokenizer.ggml.scores arr[f32,48353]   = [-1000.000000, -1000.000000, -1000.00...\n","llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,48353]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 48351\n","llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 48352\n","llama_model_loader: - kv  23:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  24:            tokenizer.ggml.padding_token_id u32              = 48352\n","llama_model_loader: - kv  25:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  26:               tokenizer.ggml.add_sep_token bool             = false\n","llama_model_loader: - kv  27:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...\n","llama_model_loader: - kv  29:            tokenizer.ggml.add_space_prefix bool             = true\n","llama_model_loader: - type  f32:  291 tensors\n","[   1/ 291]                        output.weight - [ 4096, 48353,     1,     1], type =    f32, converting to q6_K .. size =   755.52 MiB ->   154.94 MiB\n","[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[   3/ 291]                    token_embd.weight - [ 4096, 48353,     1,     1], type =    f32, converting to q4_0 .. size =   755.52 MiB ->   106.24 MiB\n","[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f32, converting to q4_0 .. size =    64.00 MiB ->     9.00 MiB\n","[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f32, converting to q4_0 .. size =    16.00 MiB ->     2.25 MiB\n","[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f32, converting to q4_0 .. size =   224.00 MiB ->    31.50 MiB\n","llama_model_quantize_impl: model size  = 28136.05 MB\n","llama_model_quantize_impl: quant size  =  4006.20 MB\n","\n","main: quantize time = 116947.10 ms\n","main:    total time = 116947.10 ms\n"]}]},{"cell_type":"code","source":["!ls -lh | grep quantize\n"],"metadata":{"id":"W7RGRLgKt4us","executionInfo":{"status":"ok","timestamp":1753533093092,"user_tz":-180,"elapsed":106,"user":{"displayName":"METE MUSUL","userId":"13780932483197271217"}}},"execution_count":7,"outputs":[]}]}